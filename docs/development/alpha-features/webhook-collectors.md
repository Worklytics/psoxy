# Webhook Collectors Spec

**ALPHA FEATURE** - This is an alpha feature, not yet available in production. Description below is for design purposes only,
and may change or not be implemented as described.

***Use case: **
   - custom tools, managed in house by customers. Customers can fire webhooks from these
tools to webhook collectors, which sanitize the data (namely, consistently pseudonymizing any PII such that it's linkable
to other data sources) and collect it into bulk data storage (e.g. S3, GCS, etc), from which it can later be transferred to Worklytics (asynchronously) for analysis.
   - on-prem / self-hosted tools (JIRA) that can be configured to fire webhooks
   - tools that fire webhooks which provide richer data than they expose via their APIs

MVP will really only support the first one, where all relevant data is send as JSON body of a webhook
request.  Webhook path, query parameters, and headers will be irrelevant to what's stored in the
bucket.

## Concept

  - **Tool Client** - Javascript or web application client, running in a user endpoint (browser, mobile, etc), that sends
    webhook payloads directly to the collector (in principle)
  - **Tool Server** - the backend server of the tool.
  - **Webhook Collector** - the instance of psoxy that collects webhooks from the Tool Client or Tool Server, and
    sanitizes the data before storing it in bulk storage (e.g. S3, GCS, etc).

## Authentication

Authentication is required to ensure *integrity* of the data collected; specifically attribution of
webhook to a specific *actor* (user) can be trusted for analysis purposes.  This will primarily be
done by each webhook including a signature token that can be verified by the collector.  The
signature token will be an JWT identity token generated by the Tool Server and securely distributed
to the Tool Client. It should be held by the Tool Client as a secret, equivalent to a session
token/cookie.

The Tool Client will include this token in the webhook payload, and the Webhook Collector will
verify it before accepting the payload.

See [jwt.io](https://jwt.io/) for more details on how to generate and verify JWT tokens in general.

`REQUIRE_AUTHORIZATION_HEADER` - env var that indicates whether the Webhook Collector requires an `Authorization` header
  to be sent. This header MUST be a valid JWT identity token, signed with one of the public keys configured in `ACCEPTED_AUTH_KEYS`.

It MUST contain:
  - `typ` (type) claim, which indicates the type of the token. This should be `JWT`.
  - `alg` (algorithm) claim, which indicates the algorithm used to sign the token. This should be `RS256`.
  - `aud` (audience) claim, which indicates the audience for which the token is intended. This should be the collector endpoint URL, eg `https://jr2e4x60sa.execute-api.us-east-1.amazonaws.com/webhook_collectors/llm-portal`.
  - `iss` (issuer) claim, which indicates the issuer of the token. This should ALSO be the collector endpoint URL.
  - `iat` (issued at) claim, which indicates when the token was issued, in seconds since the epoch. Must not be in the future.
  - `exp` (expiration) claim, which indicates when the token expires, in seconds since the epoch. Must not be more than 365 days in the future.
  - `kid` (key ID) claim, which indicates the key that was used to sign the token. This should match one of the keys in `ACCEPTED_AUTH_KEYS`.

It MAY contain:
  - `sub` (subject) claim, which indicates the user or entity that the token represents. (eg, user using the tool)
  - additional claims that the Tool Server may want to include, with, as of 0.5.3, no restrictions on semantics of those.

All of the above claims have their standard semantics per OpenID Connect and JWT specifications.

`ACCEPTED_AUTH_KEYS` - env var that references all the public keys that will be tested against the JWT identity token. if JWT
received is valid according to any of them, then the request is authenticated and authorized. Options:
   - `aws-kms:arn:aws:kms:REGION:ACCOUNT_ID:alias/ALIAS_NAME`
   - `base64:BASE64_ENCODED_PUBLIC_KEY` - must be RSA public key in base64 format
   - `gcp-kms:projects/{project}/locations/{location}/keyRings/{keyRing}/cryptoKeys/{key}/cryptoKeyVersions/{version}`

This is POTENTIALLY a CSV, if multiple keys are concurrently valid (due to rotation/migration).

In the AWS case, asymmetric key pairs CANNOT be automatically rotated, so we expect multiple keys to be configured
in the usual case. For simplicity, if you're using our Terraform modules to manage keys and rotation, we'll provision TWO keys
scheduled to expire after N and N/2 days, respectively. You should encrypt payloads with the key that expires FURTHEST in
the future (refer to the ISO-formatted timestamp in the tag `rotation_time` to determine this). You should run `terraform apply`
at least every N/2 days to ensure that the keys are rotated and the new key is provisioned.

Our module will also create a KMS key alias ending in `_signing-key`; any app you use to create auth tokens should use this alias
when signing. If rotation is enabled, this alias will be updated accordingly on every `terraform apply` to point to the correct key.  Eg,
if your environment id is `worklytics`, and your proxy webhook collection id is `llm-portal`, then alias will be `worklytics/llm-portal_signing-key`.

Alternatively, you may manage the keys yourself and pass in kms key aliases via the `auth_keys` property of the `webhook_collectors`
variable.  Have `current` and `previous` aliases point to the current and previous keys, respectively. When you rotate,
update these (previous --> current, then current to your new key). Ensure you're ALWAYS signing the auth tokens with the
`current` key.

Note that this scheme **enables authentication of the request** AND **partial integrity verification of the request/payload**.
Eg, a valid signed JWT identity token ensures that it originated with a trusted client. If you control to whom you issue
auth tokens, you can trust these as authenticated requests. Additionally, the webhook rules may validate the request/payload's
integrity for a subset of fields against the JWT claims included in the token; since these claims were signed by your private
key, you can trust that the fields you checked are authentic.  However, any unchecked fields in the payload/query string may
have been forged either by the client itself OR by a malicious actor who somehow obtained the JWT identity token.  This design
choice is intended to optimize for performance and avoid many round-trips to a trusted server to generate JWT identity tokens.
The usual scenario is that your server issues JWT token for each client session; clients send that token directly to webhook
collection endpoint with each payload; the webhook collector is able to authenticate the request and verify the integrity of the
identity of the user/client.  While users/clients may be able forge aspects of the payload, they will not be able to forge the
identity of sender of the payload.

### AWS KMS Keys + NodeJS Example
As an example, if you're using AWS KMS keys to sign the JWT identity tokens (the default using our
Terraform modules) and have a server (backend) for your Tool in NodeJS, you might create a JWT identity token
as follows

```javascript
import {KMSClient, SignCommand} from '@aws-sdk/client-kms';
import crypto from 'node:crypto';

let claims = {
      iss: 'https://jr2e4x60sa.execute-api.us-east-1.amazonaws.com/webhook_collectors/llm-portal', // the collector endpoint URL
      sub: 'alice@worklytics.co', // the user who is authenticated by the Tool Server for the Tool Client
      aud: 'https://jr2e4x60sa.execute-api.us-east-1.amazonaws.com/webhook_collectors/llm-portal', // the collector endpoint URL
      iat: Math.floor(Date.now() / 1000), // current time in seconds
      exp: Math.floor(Date.now() / 1000) + 60 * 60, // 1 hour from now; could be more;
    }


function base64url(input) {
    return input.toString('base64')
        .replace(/=/g, '')
        .replace(/\+/g, '-')
        .replace(/\//g, '_');
}

/**
 * @param {object} claims - the usual JWT ones, iss, sub, etc. will be stringified
 * @param {string} keyArn
 * @param {Credentials} credentials
 * @param {string} region
 * @returns {Promise<string>}
 */
async function signJwtWithKMS(claims, keyArn, credentials, region) {
    const client = new KMSClient({
        region: region,
        credentials: credentials,
    });

    const encodedHeader = base64url(Buffer.from(JSON.stringify({
        "alg": "RS256",
        "kid": keyArn,
        "typ": "JWT",
    })));
    const encodedPayload = base64url(Buffer.from(JSON.stringify(claims)));
    const signingInput = `${encodedHeader}.${encodedPayload}`;

    const hash = crypto.createHash('sha256').update(signingInput).digest();

    const command = new SignCommand({
        KeyId: keyArn,
        SigningAlgorithm: 'RSASSA_PKCS1_V1_5_SHA_256',
        Message: hash,
        MessageType: 'DIGEST'
    });

    const response = await client.send(command);

    const signature = base64url(Buffer.from(response.Signature));
    return `${signingInput}.${signature}`;
}

let signingKeyArn = 'arn:aws:kms:us-east-1:123456789012:key/your-key-id'; // if using our Terraform module, you can use an alias `llm-portal_signing-key`

let credentials = { }; // credentials for your AWS principal of your server, eg from AWS SDK or environment variables

// this signature should be kept secret and securely distributed to the Tool Client; anyone in possession of it can impersonate the user
// for the purposes of webhook data collection
let signature = await signJwtWithKMS(claims, signingKeyArn, credentials, 'us-east-1');
```

You would then pass the resulting token to the Tool Client, to send with every webhook request to the Webhook Collector
as the `Authorization` header.

## Data Flows

### Scenario A : Tool Client to Webhook Collector

  1. Tool Server generates a JWT identity token for the user, which is securely distributed to the Tool Client.
  2. Tool Client includes the JWT identity token in the webhook payload, sent directly to the Webhook Collector.

This is analogous to how many metric systems, such as Google Analytics, work. Some minimal server-side logic
is required to obtain the JWT identity token and distribute it to the Tool Client.

### Scenario B : Tool Server to Webhook Collector

Tool Client does NOT communicate directly with the Webhook Collector. Instead, the Tool Server sends webhook
payloads to the Webhook Collector

This requires more extensive server-side logic in the Tool Server; and may have more performance implications.

### Scenario C : Tool Client to Webhook Collector without Identity Verification

In this scenario, the Tool Client sends webhook payloads directly to the Webhook Collector, which is configured
to NOT require a JWT identity token.  This is useful when Webhook Collector can be hosted on a trusted network,
or its trust in the Tool Client can be independently established (such as with IAM/API Gateway rules in AWS


## Implementation Design

A new entry point handler; `InboundWebhookHandler` that will handle incoming webhook requests to proxy instances.
That will sanitize the payloads and write them to a bulk storage location as set in an `OUTPUT` environment variable.
   - similar approach to API case, where there are host-platform-specific wrappers around a common handler ?? prob.

Rules of type `WebhookCollectionRules`, which includes:
  - `jwtClaimsToVerify` - a list of any JWT claims that must be present in the JWT token sent in `Authorization` header
    of the incoming webhook request which must be verified against webhook payload before accepting
     the webhook payload. Keys are the JWT claim names, and value are list of places to check against that claims value
          - eg, `queryParam`, `payloadContent`, `pathParam`, etc
  - `endpoints` - a list of `WebhookEndpoint` objects, which define the endpoints that the webhook collector will
which is a list of `WebhookRule` objects; first matching rule will be applied to the incoming
webhook request. If none match, collector will return a 400 Bad Request response. Additionally


No matching in v1, so effectively just one `WebhookRule` will have the following properties:
 - `transforms` - a list (ordered) of transforms to apply to the incoming webhook payload before storing it.
 - `jwtClaimsToVerify` - a list of (additional) JWT claims that must be present in the JWT token sent in `Authorization` header
    of the incoming webhook request which must be verified against webhook payload before accepting
     the webhook payload. Keys are the JWT claim names, and value are list of places to check against that claims value
          - eg, `queryParam`, `payloadContent`, `pathParam`, etc

```yaml
jwtClaimsToVerify:
    sub:
        queryParam: "userId"
        payloadContent: "$.user_id"
        pathParam: "userId"
endpoints:
    - jwtClaimsToVerify:
        sub:
            queryParam: "userId"
            payloadContent: "$.user_id"
            pathParam: "userId"
      transforms:
      - !<pseudonymize>
         jsonPaths:
           - "$.employeeEmail"
           - "$.managerEmail"
```

Outputs will be configured as follows, using env variables:
  -


Terraform - `gcp-webhook-collector` and `aws-webhook-collector` modules that will deploy the necessary infrastructure. These will:
   - provision `-output` bucket for bulk storage of webhook payloads, readable to caller IAM role/principal (e.g. Worklytics tenant)


Webhooks will always be written as NDJSON (newline-delimited JSON) to the output bucket.

To do this efficiently, we'd split into 2 steps: 1) webhook collector that receives webhook payload, accepts + sanitizes it, and then sends it to SQS. Then separately
a trigger that 2) batches messages from SQS and writes them to the output bucket as NDJSON files.

https://docs.aws.amazon.com/lambda/latest/dg/services-sqs-configure.html

To handle both in same lambda, we need `WebhookCollectionModeHandler` to handle streams, and
parse whether those are direct invocations of the webhook collector or SQS message batches

if webhook, then logic will:
- verify the JWT identity token in the `Authorization` header
- apply the transforms to the payload
- write the sanitized payload to SQS

if batch, then logic will:
- read message(s) from SQS
- batch them into NDJSON files
- write the NDJSON files to the output bucket

### Future

#### Authentication beyond Tokens
Additional authentication checks:
- IP range of request
- VPC - lock collectors to ONLY being reachable from specific VPC(s)

#### Collect Originals
Optionally, an `OUTPUT_ORIGINAL` environment variable can be set to store the original payloads in a different bucket/location.


#### Add FILTERS
- `method` - HTTP method (GET, POST, etc) that the rule applies to [ do we care?? maybe security to lock to `POST` if/when possible]
- `pathTemplate` - a path template that matches the incoming webhook request path. `null` means all paths are accepted.
- `pathParamFilters` - if defined, request must pass these path parameter filters to be accepted.
- `queryParamFilters` - if defined, request must pass  these query parameter filters to be accepted.
- `format` - `payload`, `request` - only support `payload` for now, which means the payload is stored as-is.
- `filters` - a list of filters to apply to the incoming webhook payload before storing it; `JSONSchemaFilter` implementation.

Add a `REQUEST` format for writing webhooks --> storage:
```json
{
    "timeReceived": "2023-10-01T12:00:00Z",
    "path": "/webhook/path",
    "method": "POST",
    "queryParameters": {
        "param1": "value1",
        "param2": "value2"
    },
    "payload": {
        "key1": "value1",
        "key2": "value2"
    }
}
```

Ideally, we want to batch many payloads into a single NDJSON file, which we'd then compress and store in the output bucket.

To do this reliably/efficiently, I think we need to add SQS in the middle, which can batch up to 10k messages.


### Issues


  - directly include JSON payloads OR serialize?
     - eg `"payload": "{...}"` OR `"payload": {...}` ? former more extensible, latter more concise / usable, if have polymorphic types
  - holding open socket to file, appending NDJSON continually ... seems like this might not work due to sleeping lambdas/functions between requests?
    let's try it, and be sure to retry-
  - JIRA webhooks include PII in the path/query string. How to deal with this??
      - `queryString` transforms, expecting json path stuff. [what if param included multiple times?]
  - JIRA webhooks can mix a bunch of events of different schemas via single callback
  - need filters of some kind? (eg, avoid storage/processing of webhook payloads that don't have expected schemas?)
  - routing based on `method`, `path`, `queryParameters`?
  - is there EVER a need to store headers?
